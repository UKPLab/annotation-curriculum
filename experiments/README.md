# Annotation Curricula

> This repository contains experimental software and is published for the sole purpose of giving additional background 
> details on the respective publication.

## Setup

    conda create -n ac
    source activate ac 
    conda install pip
    pip install -r requirements.txt

## Data

### Download data

You can download and preprocess the data for `SigIE` and `SPEC` by running

	python scripts/download_data.py
	python scripts/prepare_data.py

The raw datasets are available [here](http://pages.cs.wisc.edu/~bsettles/data/).
Muc7T needs to be purchased from the Linguistic Data Consortium, extracted and
put into the `data` folder. Your folders should look like

    annotation-curriculum\experiments\data
    ├───external
    │   └───muc7t
    └───processed
        ├───conll2003
        ├───sigie
        └───spec

## Splits

The data splits can be generated by running 

    python scripts/datasets.py

and then are under `results/splits`. For SPEC, we use the first column as the id
(PubMed abstract id + sentence number), for SigIE the first colum as well
(the source Sig+Reply file ID) and for Muc7T the Muc7 file name + document id +
sentence id seperated by colons.

## Simulation (Section 4)

The simulation can be run via:

    python curriculum_annotation.py simulation

By default, the simulation includes the SIGIE, SPEC, and MUC data. To remove individual datasets, 
remove them from the list of experiments in line 58 in `curriculum_annotation.py` .
For debugging purposes, you can also reduce the number of instances each experiment is run using
the `[--debug_limit=<debug_limit>]` option. The results from the simulation will be pooled 
in the respective `results` folder. 

## Hyperparameter Tuning

All our experiments for model selection and hyperparameter tuning can be found under `ca/experiments/` .

## Userstudy runner

In order for the user study to run, it needs a web server (see the `userstudy` folder above) and the server that performs
the actual training and curriculum (this is in `userstudy_runner`). Run the `app.py` in `userstudy_runner`. Example requets
and responses can be found under `userstudy_runner/{predict.json|predict.json}`.

